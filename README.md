# MD4SG-ALP-Spring24
This is the repository for the [**Algorithms, Law, and Policy Working Group**](https://www.md4sg.com/workinggroups/lawpolicy) (Spring 2024), a [Mechanism Design for Social Good (MD4SG)](https://www.md4sg.com/index.html) working group.

# Program:

## Topics of interest:
Our focus this term is on exploring global perspectives on AI policy and regulation. In each session, we will discuss one concrete policy issue. We hope to identify available policy and technical options, understand rationals behind different policy choices, and understand areas of global consensus and divergence. We are currently putting together a schedule to plan biweekly meetings between January and May 2024. Sessions will be a mix of **invited speakers**, **presentations by group members**, and **guided readings and discussions**.

We warmly welcome group member presentation on but not limited to following concrete AI governance issues, with the hope to understand policy and technical options, rationals, and areas of global consensus and divergence:
1. Can AI generated content have copyright?
  - Beijing court finds AI-generated image is copyrightable, [link](https://www.lexology.com/library/detail.aspx?g=320bf8d7-fa98-4e43-9237-0487e5cfc88d#:~:text=In%20a%20decision%20issued%5B1,may%20have%20far%2Dreaching%20implications).
  - [Opinion](https://www.project-syndicate.org/commentary/risks-of-beijing-internet-court-ruling-allowing-copyright-of-ai-generated-content-by-angela-huyue-zhang-2023-12?barrier=accesspaylog) from prof Angela Huyue Zhang on Beijing’s ruling: Chinese authorities have become fixated on ensuring that the country can surpass the US to become the global leader in artificial intelligence. Short-sighted.
  - US: a work entirely created by an AI cannot be protected under copyright. See [here](https://www.august-debouzy.com/en/blog/1997-first-ruling-by-a-us-court-for-ai-generated-content-and-copyright-protection), and [here](https://www.spiceworks.com/tech/artificial-intelligence/news/us-copyright-law-ai-generated-content/).
  - A [discussion](https://www.ddg.fr/actualite/copyright-protection-for-generative-aigenerated-content-would-american-and-chinese-approaches-be-contradictory) on China and US’s approaches
2. Can AI be trained on copyrighted data?
  - In OpenAI's [written evidence](https://committees.parliament.uk/writtenevidence/126981/pdf/) to UK parliament: Because copyright today covers virtually every sort of human expression, it would be impossible to train today’s leading AI models without using copyrighted materials.
  - One of the key disputes is whether training generative AI models on copyrighted work is a “fair use”.
  - The use of copyrighted data for AI training is supported in [Japan](https://twitter.com/hardmaru/status/1664146242262425606?s=20), [Israel](https://twitter.com/hardmaru/status/1664149095836188672?s=20). Japan’s view may be [changing](https://asia.nikkei.com/Business/Technology/Japan-panel-pushes-to-shield-copyrighted-work-from-AI-training).
  - ccording to the [December 2023 text of the EU AI Act](https://www.openfuture.eu/wp-content/uploads/2023/12/231206GPAI_Compromise_proposalv4.pdf): Any use of copyright protected content requires the authorization of the rightholder unless relevant copyright exceptions. Any provider placing a general-purpose AI model on the EU market should comply with this obligation, regardless of where the training of these models take place. no providers should be able to gain a competitive advantage by placing a lower copyright standard than those provided in the EU.
  - Major court cases have been filed in the US, including [New York Times v. OpenAI](https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf), [visual artists v. Stability AI](https://www.reuters.com/legal/transactional/lawsuits-accuse-ai-content-creators-misusing-copyrighted-work-2023-01-17/).
  - A good review of this issue on Japan, EU, and US: [link](https://www.mintz.com/insights-center/viewpoints/54731/2024-01-10-unfair-use-copyrighted-works-ai-training-data-ai)
  - OpenAI’s [response](https://openai.com/blog/openai-and-journalism) to NY Times.
3. compute threshold approach to regulate foundation model
  - The US white house’s executive order takes a [threshold approach](https://hai.stanford.edu/news/decoding-white-house-ai-executive-orders-achievements) to regulate foundation models. Many requirements, including to report red-teaming results, ownership of the weights, etc., apply to for foundation models above a given threshold of compute.
  - Andrew Ng’s [criticism](https://twitter.com/AndrewYNg/status/1719474906138607650?s=20) on the compute threshold approach.
4. Should foundation models be regulated?
  - Many are against regulating foundation models, including [Andrew Ng](https://twitter.com/AndrewYNg/status/1719474906138607650?s=20), [Yann LeCun](https://twitter.com/ylecun/status/1734674441806782830?s=20), and [LAION](https://twitter.com/JJitsev/status/1731794689647399191?s=20).
  - The criticism mainly is on its negative impact on science, research, and the advancement of AI. Openness and accessibility should not be sacrificed
  - The alternative solution the critics support is to regulate at the application level
  - Many [support](https://ainowinstitute.org/publication/gpai-is-high-risk-should-not-be-excluded-from-eu-ai-act) the regulation of foundation models, because they are powerful, general-purpose, and could be dual-used.
5. Whether/How to regulate open-source datasets/models?
  - Child sex abuse material found in LAION, [link](https://www.404media.co/laion-datasets-removed-stanford-csam-child-abuse/)
  - Some argue against regulating open-source data/models, e.g., [Yann LeCun](https://twitter.com/ylecun/status/1733481002234679685?lang=en)
6. what value to align AI to
  - China's interim guidelines for generative AI services requires alignment with socialist values, [link](https://dig.watch/updates/chinas-interim-guidelines-for-generative-ai-services)
  - AI in Europe need to respect fundamental rights and democracy, [link](https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai)
  - Taiwan builds own LLM to counter China's influence, [link](https://www.bloomberg.com/news/articles/2024-01-25/taiwan-builds-own-ai-language-model-to-counter-china-s-influence?utm_source=website&utm_medium=share&utm_campaign=twitter)


## Tentative Schedule:
_tbd_

## Invited speakers:
- Jonas Geiping (ELLIS Institute & MPI-IS Tübingen)
- Prof. Angela Huyue Zhang (The University of Hong Kong)
- Prof. Simon Chesterman (National University of Singapore)
- Prof. Dr. Michèle Finck, LL.M. (University of Tübingen)
- Sayash Kapoor (Princeton University)

# Organizers:
If you are interested in joining this working group, please reach out to one of the organizers:
- [Joachim Baumann](https://www.ifi.uzh.ch/en/scg/people/Baumann.html)
- [Xudong Shen](https://xudongolivershen.github.io/)

With a lot of help from [Ana-Andreea Stoica](http://www.columbia.edu/~as5001/), [Thomas Gilbert](https://www.thomaskrendlgilbert.com/), and [Ayse Yasar](https://www.lse.ac.uk/law/people/academic-staff/ayse-gizem-yasar).
